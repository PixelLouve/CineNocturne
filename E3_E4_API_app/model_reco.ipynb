{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb41c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# 1. Charger les données\n",
    "query = \"SELECT movie_id, title, genres, synopsis FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# 2. Nettoyage\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# 3. Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=30000, \n",
    "    ngram_range=(1,3), \n",
    "    stop_words=\"english\", \n",
    "    sublinear_tf=True,\n",
    "    norm='l2', \n",
    "    min_df=5, \n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"synopsis_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# lancement : mlflow ui\n",
    "\n",
    "# ------------------------------\n",
    "# Connexion MLflow\n",
    "# ------------------------------\n",
    "mlflow.set_experiment(\"movie_cosine_similarity_test\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"TFIDF_Cosine_Test\") as run:\n",
    "    # ------------------------------\n",
    "    # Paramètres TF-IDF à logger\n",
    "    # ------------------------------\n",
    "    max_features = 80000\n",
    "    ngram_range = (1,3)\n",
    "    min_df = 5\n",
    "    max_df = 0.8\n",
    "    sublinear_tf = True\n",
    "    norm = 'l2'\n",
    "\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "    mlflow.log_param(\"ngram_range\", ngram_range)\n",
    "    mlflow.log_param(\"min_df\", min_df)\n",
    "    mlflow.log_param(\"max_df\", max_df)\n",
    "    mlflow.log_param(\"sublinear_tf\", sublinear_tf)\n",
    "    mlflow.log_param(\"norm\", norm)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Préprocessing\n",
    "    # ------------------------------\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "    # ------------------------------\n",
    "    # TF-IDF\n",
    "    # ------------------------------\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range,\n",
    "        stop_words=\"english\",\n",
    "        sublinear_tf=sublinear_tf,\n",
    "        norm=norm,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df\n",
    "    )\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"synopsis_clean\"])\n",
    "\n",
    "    # ------------------------------\n",
    "    # Sample pour test\n",
    "    # ------------------------------\n",
    "    sample_df = df.sample(5, random_state=42)\n",
    "    closest_movies = []\n",
    "\n",
    "    for idx, row in sample_df.iterrows():\n",
    "        cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
    "        cosine_sim[idx] = -1  # ignorer lui-même\n",
    "        top_idx = cosine_sim.argmax()\n",
    "        closest_movies.append({\n",
    "            \"Tested Movie\": row['title'],\n",
    "            \"Closest Movie\": df.iloc[top_idx]['title'],\n",
    "            \"Cosine Score\": cosine_sim[top_idx]\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(closest_movies)\n",
    "    print(result_df)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Logger dans MLflow\n",
    "    # ------------------------------\n",
    "    mlflow.log_metric(\"mean_cosine_score\", result_df['Cosine Score'].mean())\n",
    "\n",
    "    # Optionnel : log dataframe complet comme artifact CSV\n",
    "    result_df.to_csv(\"cosine_test_results.csv\", index=False)\n",
    "    mlflow.log_artifact(\"cosine_test_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f04c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# 1. Charger les données\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "query = \"SELECT movie_id, title, synopsis, rating, genres FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Nettoyage\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# Genres en liste\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: [g.strip() for g in x.split(\",\")])\n",
    "\n",
    "# Sample pour limiter mémoire\n",
    "df_sample = df.sample(10_000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# TF-IDF + SVD\n",
    "# =========================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(df_sample[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# =========================\n",
    "# Nearest Neighbors\n",
    "# =========================\n",
    "nn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn.fit(tfidf_matrix)\n",
    "distances, indices = nn.kneighbors(tfidf_matrix, n_neighbors=10)  # 10 voisins\n",
    "neighbors = indices[:, 1:]\n",
    "neighbor_scores = 1 - distances[:, 1:]\n",
    "\n",
    "sim_mean = neighbor_scores.mean(axis=1)\n",
    "sim_max = neighbor_scores.max(axis=1)\n",
    "sim_min = neighbor_scores.min(axis=1)\n",
    "sim_std = neighbor_scores.std(axis=1)\n",
    "\n",
    "# =========================\n",
    "# Genres one-hot\n",
    "# =========================\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_ohe = mlb.fit_transform(df_sample[\"genres_list\"])\n",
    "\n",
    "# =========================\n",
    "# Target binaire : like ou pas\n",
    "# =========================\n",
    "df_sample[\"like\"] = (df_sample[\"rating\"] >= 7).astype(int)\n",
    "\n",
    "# =========================\n",
    "# Construction features\n",
    "# =========================\n",
    "X = np.column_stack([tfidf_svd, sim_mean, sim_max, sim_min, sim_std, genres_ohe])\n",
    "y = df_sample[\"like\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# MLflow tracking\n",
    "# =========================\n",
    "mlflow.set_experiment(\"movies_reco_classification\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"hybrid_cosine_xgb_classif\"):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "    mlflow.xgboost.log_model(model, \"xgb_model_classif\")\n",
    "\n",
    "    # =========================\n",
    "    # Fonction recommandations\n",
    "    # =========================\n",
    "    def recommend_movies(model, movie_id, user_rating=8, top_k=5):\n",
    "        idx = df_sample.index[df_sample[\"movie_id\"] == movie_id][0]\n",
    "        neighbor_idx = neighbors[idx]\n",
    "        sims = neighbor_scores[idx]\n",
    "\n",
    "        rec_movies = []\n",
    "        rec_features = []\n",
    "\n",
    "        for i, sim_score in zip(neighbor_idx, sims):\n",
    "            rec_movies.append(df_sample.iloc[i][\"title\"])\n",
    "            feat = np.hstack([\n",
    "                tfidf_svd[i],\n",
    "                sim_mean[i],\n",
    "                sim_max[i],\n",
    "                sim_min[i],\n",
    "                sim_std[i],\n",
    "                genres_ohe[i]\n",
    "            ])\n",
    "            rec_features.append(feat)\n",
    "\n",
    "        rec_features = scaler.transform(np.array(rec_features))\n",
    "        pred_scores = model.predict_proba(rec_features)[:,1]\n",
    "\n",
    "        # Pondération par la note de l'utilisateur\n",
    "        pred_scores *= (user_rating / 10)\n",
    "\n",
    "        top_idx = np.argsort(pred_scores)[-top_k:][::-1]\n",
    "        return [(rec_movies[i], pred_scores[i]) for i in top_idx]\n",
    "\n",
    "    # Exemple\n",
    "    movie_id = df_sample.iloc[0][\"movie_id\"]\n",
    "    recommendations = recommend_movies(model, movie_id, user_rating=9)\n",
    "\n",
    "    rec_df = pd.DataFrame(recommendations, columns=[\"title\", \"pred_score\"])\n",
    "    rec_df.to_csv(\"recommendations_classif.csv\", index=False)\n",
    "    mlflow.log_artifact(\"recommendations_classif.csv\")\n",
    "\n",
    "print(\"✅ Pipeline terminé ! Accuracy:\", acc, \"| AUC:\", auc)\n",
    "print(\"✅ Recommandations exemples :\\n\", rec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9793c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "# =========================\n",
    "# 1. Charger les données\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "query = \"SELECT movie_id, title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Nettoyage texte\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# Sample pour limiter la mémoire\n",
    "df_sample = df.sample(10_000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# TF-IDF + SVD\n",
    "# =========================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(df_sample[\"synopsis_clean\"].fillna(\"\"))\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# =========================\n",
    "# Encodage genres\n",
    "# =========================\n",
    "df_sample[\"genres_list\"] = df_sample[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = mlb.fit_transform(df_sample[\"genres_list\"])\n",
    "\n",
    "# =========================\n",
    "# Normalisation année de sortie\n",
    "# =========================\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled = scaler_year.fit_transform(df_sample[[\"release_year\"]].fillna(df_sample[\"release_year\"].mean()))\n",
    "\n",
    "# =========================\n",
    "# Nearest Neighbors (Cosine sur TF-IDF)\n",
    "# =========================\n",
    "nn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn.fit(tfidf_matrix)\n",
    "distances, indices = nn.kneighbors(tfidf_matrix, n_neighbors=6)\n",
    "neighbors = indices[:, 1:]\n",
    "neighbor_scores = 1 - distances[:, 1:]\n",
    "\n",
    "# Features statistiques des voisins\n",
    "sim_mean = neighbor_scores.mean(axis=1)\n",
    "sim_max = neighbor_scores.max(axis=1)\n",
    "sim_min = neighbor_scores.min(axis=1)\n",
    "sim_std = neighbor_scores.std(axis=1)\n",
    "\n",
    "# =========================\n",
    "# Construction features X\n",
    "# =========================\n",
    "rating_norm = df_sample[\"rating\"] / 10.0  # note sur 10\n",
    "X = np.column_stack([tfidf_svd, genres_encoded, year_scaled, sim_mean, sim_max, sim_min, sim_std, rating_norm])\n",
    "y = df_sample[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# MLflow Tracking\n",
    "# =========================\n",
    "mlflow.set_experiment(\"movies_reco_pipeline_hybrid_v2\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"cosine_xgboost_genres_year\"):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    # Log modèle\n",
    "    mlflow.xgboost.log_model(model, \"xgboost_model\")\n",
    "\n",
    "    # =========================\n",
    "    # Fonction de recommandation\n",
    "    # =========================\n",
    "    def recommend_movies(model, movie_id, user_rating=8.0, top_k=5):\n",
    "        idx = df_sample.index[df_sample[\"movie_id\"] == movie_id][0]\n",
    "\n",
    "        neighbor_idx = neighbors[idx]\n",
    "        sims = neighbor_scores[idx]\n",
    "\n",
    "        rec_movies = []\n",
    "        rec_features = []\n",
    "\n",
    "        for i, sim_score in zip(neighbor_idx, sims):\n",
    "            rec_movies.append(df_sample.iloc[i][\"title\"])\n",
    "            feat = np.hstack([\n",
    "                tfidf_svd[i],\n",
    "                genres_encoded[i],\n",
    "                year_scaled[i],\n",
    "                sim_mean[i],\n",
    "                sim_max[i],\n",
    "                sim_min[i],\n",
    "                sim_std[i],\n",
    "                user_rating / 10.0  # pondération selon note utilisateur\n",
    "            ])\n",
    "            rec_features.append(feat)\n",
    "\n",
    "        rec_features = np.array(rec_features)\n",
    "        pred_scores = model.predict(rec_features)\n",
    "\n",
    "        top_idx = np.argsort(pred_scores)[-top_k:][::-1]\n",
    "        recommended = [(rec_movies[i], pred_scores[i]) for i in top_idx]\n",
    "        return recommended\n",
    "\n",
    "    # Exemple test\n",
    "    movie_id = df_sample.iloc[0][\"movie_id\"]\n",
    "    user_rating = 8.0\n",
    "    recommendations = recommend_movies(model, movie_id, user_rating)\n",
    "\n",
    "    rec_df = pd.DataFrame(recommendations, columns=[\"title\", \"pred_score\"])\n",
    "    rec_df.to_csv(\"recommendations_v2.csv\", index=False)\n",
    "    mlflow.log_artifact(\"recommendations_v2.csv\")\n",
    "\n",
    "print(\"✅ Pipeline terminé ! RMSE:\", rmse, \"| R²:\", r2)\n",
    "print(\"✅ Recommandations exemples :\")\n",
    "print(rec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c956d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:19:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/26 16:19:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [16:19:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/08/26 16:19:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline classification terminé ! Accuracy: 0.832 | AUC: 0.5694185487226879\n",
      "✅ Modèle XGB sauvegardé !\n",
      "✅ TfidfVectorizer sauvegardé !\n",
      "✅ SVD sauvegardé !\n",
      "✅ TF-IDF matrix complète sauvegardée !\n",
      "✅ Movie index complet sauvegardé !\n",
      "✅ MultiLabelBinarizer sauvegardé !\n",
      "✅ StandardScaler pour l'année sauvegardé !\n",
      "✅ NearestNeighbors complet sauvegardé !\n",
      "✅ DataFrame complet sauvegardé !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# 1. Charger les données\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "query = \"SELECT movie_id, title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Nettoyage texte\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# =========================\n",
    "# 2. TF-IDF + SVD sur tout le dataset\n",
    "# =========================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "svd_full = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_svd_full = svd_full.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# =========================\n",
    "# 3. Genres et années\n",
    "# =========================\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(df[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "# =========================\n",
    "# 4. Nearest Neighbors sur full dataset\n",
    "# =========================\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, indices_full = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "# =========================\n",
    "# 5. Échantillon pour entraînement XGB\n",
    "# =========================\n",
    "df_sample = df.sample(10_000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "tfidf_matrix_sample = vectorizer.transform(df_sample[\"synopsis_clean\"].fillna(\"\"))\n",
    "tfidf_svd_sample = svd_full.transform(tfidf_matrix_sample)\n",
    "\n",
    "genres_encoded_sample = mlb.transform(df_sample[\"genres_list\"])\n",
    "year_scaled_sample = scaler_year.transform(df_sample[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "nn_sample = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_sample.fit(tfidf_matrix_sample)\n",
    "distances_sample, indices_sample = nn_sample.kneighbors(tfidf_matrix_sample, n_neighbors=6)\n",
    "neighbor_scores_sample = 1 - distances_sample[:, 1:]\n",
    "\n",
    "sim_mean_sample = neighbor_scores_sample.mean(axis=1)\n",
    "sim_max_sample = neighbor_scores_sample.max(axis=1)\n",
    "sim_min_sample = neighbor_scores_sample.min(axis=1)\n",
    "sim_std_sample = neighbor_scores_sample.std(axis=1)\n",
    "\n",
    "# Classification : like / dislike\n",
    "threshold = 7.0  # note >= 7 -> \"like\"\n",
    "y_class_sample = (df_sample[\"rating\"] >= threshold).astype(int)\n",
    "\n",
    "# Features\n",
    "X_sample = np.column_stack([\n",
    "    tfidf_svd_sample,\n",
    "    genres_encoded_sample,\n",
    "    year_scaled_sample,\n",
    "    sim_mean_sample,\n",
    "    sim_max_sample,\n",
    "    sim_min_sample,\n",
    "    sim_std_sample\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_class_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# 6. MLflow & XGB\n",
    "# =========================\n",
    "mlflow.set_experiment(\"movies_reco_pipeline_classif\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_hybrid_classif\"):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.xgboost.log_model(model, \"xgb_classifier_model\")\n",
    "\n",
    "print(\"✅ Pipeline classification terminé ! Accuracy:\", acc, \"| AUC:\", auc)\n",
    "\n",
    "# =========================\n",
    "# 7. Sauvegarde des artefacts\n",
    "# =========================\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "joblib.dump(model, \"model/xgb_classifier_model.joblib\")\n",
    "print(\"✅ Modèle XGB sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du vectorizer\n",
    "joblib.dump(vectorizer, \"model/reco_vectorizer.joblib\")\n",
    "print(\"✅ TfidfVectorizer sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du SVD\n",
    "joblib.dump(svd_full, \"model/svd_model.joblib\")\n",
    "print(\"✅ SVD sauvegardé !\")\n",
    "\n",
    "# Sauvegarde de la TF-IDF matrix complète\n",
    "joblib.dump(tfidf_matrix_full, \"model/tfidf_matrix_full.joblib\")\n",
    "print(\"✅ TF-IDF matrix complète sauvegardée !\")\n",
    "\n",
    "# Sauvegarde du movie index\n",
    "df[[\"title\"]].to_csv(\"model/movie_index.csv\", index=False)\n",
    "print(\"✅ Movie index complet sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du MultiLabelBinarizer\n",
    "joblib.dump(mlb, \"model/mlb_model.joblib\")\n",
    "print(\"✅ MultiLabelBinarizer sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du StandardScaler pour l'année\n",
    "joblib.dump(scaler_year, \"model/scaler_year.joblib\")\n",
    "print(\"✅ StandardScaler pour l'année sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du NearestNeighbors complet\n",
    "joblib.dump(nn_full, \"model/nn_full.joblib\")\n",
    "print(\"✅ NearestNeighbors complet sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du DataFrame complet\n",
    "df.to_csv(\"model/movies_full.csv\", index=False)\n",
    "print(\"✅ DataFrame complet sauvegardé !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
