{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d8a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff6511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ⚙️ Config\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "SQL_QUERY = \"\"\"\n",
    "SELECT movie_id, title, synopsis, rating, genres, release_year\n",
    "FROM movies\n",
    "WHERE synopsis IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "EXPERIMENT_NAME = \"movies_hybrid_like_dislike\"\n",
    "RUN_NAME = \"xgb_hybrid_like_dislike\"\n",
    "\n",
    "LIKE_THRESHOLD = 4.0          # seuil like/dislike\n",
    "TFIDF_MAX_FEATURES = 5000\n",
    "SVD_COMPONENTS = 100\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 10_000          # None = tout le dataset\n",
    "\n",
    "ARTIFACT_DIR = \"model\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b37246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_year</th>\n",
       "      <th>synopsis_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>911430</td>\n",
       "      <td>F1</td>\n",
       "      <td>Racing legend Sonny Hayes is coaxed out of ret...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>racing legend sonny hayes is coaxed out of ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575265</td>\n",
       "      <td>Mission: Impossible - The Final Reckoning</td>\n",
       "      <td>Ethan Hunt and team continue their search for ...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>ethan hunt and team continue their search for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1061474</td>\n",
       "      <td>Superman</td>\n",
       "      <td>Superman, a journalist in Metropolis, embarks ...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>superman  a journalist in metropolis  embarks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1151334</td>\n",
       "      <td>Eenie Meanie</td>\n",
       "      <td>A former teenage getaway driver gets dragged b...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>a former teenage getaway driver gets dragged b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234821</td>\n",
       "      <td>Jurassic World Rebirth</td>\n",
       "      <td>Five years after the events of Jurassic World ...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Action</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>five years after the events of jurassic world ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                      title  \\\n",
       "0    911430                                         F1   \n",
       "1    575265  Mission: Impossible - The Final Reckoning   \n",
       "2   1061474                                   Superman   \n",
       "3   1151334                               Eenie Meanie   \n",
       "4   1234821                     Jurassic World Rebirth   \n",
       "\n",
       "                                            synopsis  rating  genres  \\\n",
       "0  Racing legend Sonny Hayes is coaxed out of ret...     7.8  Action   \n",
       "1  Ethan Hunt and team continue their search for ...     7.2  Action   \n",
       "2  Superman, a journalist in Metropolis, embarks ...     7.6  Action   \n",
       "3  A former teenage getaway driver gets dragged b...     6.8  Action   \n",
       "4  Five years after the events of Jurassic World ...     6.4  Action   \n",
       "\n",
       "   release_year                                     synopsis_clean  \n",
       "0        2025.0  racing legend sonny hayes is coaxed out of ret...  \n",
       "1        2025.0  ethan hunt and team continue their search for ...  \n",
       "2        2025.0  superman  a journalist in metropolis  embarks ...  \n",
       "3        2025.0  a former teenage getaway driver gets dragged b...  \n",
       "4        2025.0  five years after the events of jurassic world ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "df = pd.read_sql(SQL_QUERY, engine)\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].fillna(\"\").apply(preprocess_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a37894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"])\n",
    "\n",
    "# Réduction SVD\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=RANDOM_STATE)\n",
    "tfidf_svd_full = svd.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# Genres\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# Année\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(\n",
    "    df[[\"release_year\"]].fillna(df[\"release_year\"].mean())\n",
    ")\n",
    "\n",
    "# Similarité kNN\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, _ = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "sim_stats_full = np.column_stack([sim_mean_full, sim_max_full, sim_min_full, sim_std_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f30b325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 124), (10000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label binaire\n",
    "y = (df[\"rating\"] >= LIKE_THRESHOLD).astype(int).to_numpy()\n",
    "\n",
    "# Features\n",
    "X_full = np.column_stack([tfidf_svd_full, genres_encoded_full, year_scaled_full, sim_stats_full])\n",
    "\n",
    "# Échantillonnage optionnel\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(len(df), size=SAMPLE_SIZE, replace=False)\n",
    "    X = X_full[idx]\n",
    "    y = y[idx]\n",
    "    df_used = df.iloc[idx].reset_index(drop=True)\n",
    "else:\n",
    "    X = X_full\n",
    "    df_used = df.reset_index(drop=True)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f20115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 4903, Neg: 3097, scale_pos_weight=0.63\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "n_pos = int((y_train == 1).sum())\n",
    "n_neg = int((y_train == 0).sum())\n",
    "scale_pos_weight = (n_neg / n_pos) if n_pos > 0 else 1.0\n",
    "\n",
    "print(f\"Pos: {n_pos}, Neg: {n_neg}, scale_pos_weight={scale_pos_weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66b94b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/28 09:55:59 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:55:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/28 09:56:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [09:56:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/08/28 09:56:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics — ACC: 0.6675 | ROC-AUC: 0.6770 | P: 0.7049 | R: 0.7871 | F1: 0.7437\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "    }\n",
    "    mlflow.log_param(\"like_threshold\", LIKE_THRESHOLD)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"roc_auc\", roc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"xgb_hybrid_like_dislike_model\")\n",
    "\n",
    "print(f\"✅ Metrics — ACC: {acc:.4f} | ROC-AUC: {roc:.4f} | P: {prec:.4f} | R: {rec:.4f} | F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975a6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[370 404]\n",
      " [261 965]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53       774\n",
      "           1       0.70      0.79      0.74      1226\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.65      0.63      0.64      2000\n",
      "weighted avg       0.66      0.67      0.66      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b638c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Artefacts sauvegardés dans model\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, os.path.join(ARTIFACT_DIR, \"xgb_classifier_model.joblib\"))\n",
    "joblib.dump(vectorizer, os.path.join(ARTIFACT_DIR, \"reco_vectorizer.joblib\"))\n",
    "joblib.dump(svd, os.path.join(ARTIFACT_DIR, \"svd_model.joblib\"))\n",
    "joblib.dump(tfidf_matrix_full, os.path.join(ARTIFACT_DIR, \"tfidf_matrix_full.joblib\"))\n",
    "joblib.dump(mlb, os.path.join(ARTIFACT_DIR, \"mlb_model.joblib\"))\n",
    "joblib.dump(scaler_year, os.path.join(ARTIFACT_DIR, \"scaler_year.joblib\"))\n",
    "joblib.dump(nn_full, os.path.join(ARTIFACT_DIR, \"nn_full.joblib\"))\n",
    "\n",
    "#df[[\"movie_id\", \"title\"]].to_csv(os.path.join(ARTIFACT_DIR, \"movie_index_full.csv\"), index=False)\n",
    "#df.to_csv(os.path.join(ARTIFACT_DIR, \"movies_full.csv\"), index=False)\n",
    "\n",
    "print(\"🎉 Artefacts sauvegardés dans\", ARTIFACT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c956d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\loulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\loulo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:13:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/28 13:13:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\loulo\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [13:13:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/08/28 13:13:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline classification terminé ! Accuracy: 0.832 | AUC: 0.5694185487226879\n",
      "✅ Modèle XGB sauvegardé !\n",
      "✅ TfidfVectorizer sauvegardé !\n",
      "✅ SVD sauvegardé !\n",
      "✅ TF-IDF matrix complète sauvegardée !\n",
      "✅ Movie index complet sauvegardé !\n",
      "✅ MultiLabelBinarizer sauvegardé !\n",
      "✅ StandardScaler pour l'année sauvegardé !\n",
      "✅ NearestNeighbors complet sauvegardé !\n",
      "✅ DataFrame complet sauvegardé !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# =========================\n",
    "# 1. Charger les données\n",
    "# =========================\n",
    "DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "query = \"SELECT movie_id, title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Nettoyage texte\n",
    "def preprocess_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# =========================\n",
    "# 2. TF-IDF + SVD sur tout le dataset\n",
    "# =========================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix_full = vectorizer.fit_transform(df[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "svd_full = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_svd_full = svd_full.fit_transform(tfidf_matrix_full)\n",
    "\n",
    "# =========================\n",
    "# 3. Genres et années\n",
    "# =========================\n",
    "df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded_full = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "scaler_year = StandardScaler()\n",
    "year_scaled_full = scaler_year.fit_transform(df[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "# =========================\n",
    "# 4. Nearest Neighbors sur full dataset\n",
    "# =========================\n",
    "nn_full = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_full.fit(tfidf_matrix_full)\n",
    "distances_full, indices_full = nn_full.kneighbors(tfidf_matrix_full, n_neighbors=6)\n",
    "neighbor_scores_full = 1 - distances_full[:, 1:]\n",
    "\n",
    "sim_mean_full = neighbor_scores_full.mean(axis=1)\n",
    "sim_max_full = neighbor_scores_full.max(axis=1)\n",
    "sim_min_full = neighbor_scores_full.min(axis=1)\n",
    "sim_std_full = neighbor_scores_full.std(axis=1)\n",
    "\n",
    "# =========================\n",
    "# 5. Échantillon pour entraînement XGB\n",
    "# =========================\n",
    "df_sample = df.sample(10_000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "tfidf_matrix_sample = vectorizer.transform(df_sample[\"synopsis_clean\"].fillna(\"\"))\n",
    "tfidf_svd_sample = svd_full.transform(tfidf_matrix_sample)\n",
    "\n",
    "genres_encoded_sample = mlb.transform(df_sample[\"genres_list\"])\n",
    "year_scaled_sample = scaler_year.transform(df_sample[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "nn_sample = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_sample.fit(tfidf_matrix_sample)\n",
    "distances_sample, indices_sample = nn_sample.kneighbors(tfidf_matrix_sample, n_neighbors=6)\n",
    "neighbor_scores_sample = 1 - distances_sample[:, 1:]\n",
    "\n",
    "sim_mean_sample = neighbor_scores_sample.mean(axis=1)\n",
    "sim_max_sample = neighbor_scores_sample.max(axis=1)\n",
    "sim_min_sample = neighbor_scores_sample.min(axis=1)\n",
    "sim_std_sample = neighbor_scores_sample.std(axis=1)\n",
    "\n",
    "# Classification : like / dislike\n",
    "threshold = 7.0  # note >= 7 -> \"like\"\n",
    "y_class_sample = (df_sample[\"rating\"] >= threshold).astype(int)\n",
    "\n",
    "# Features\n",
    "X_sample = np.column_stack([\n",
    "    tfidf_svd_sample,\n",
    "    genres_encoded_sample,\n",
    "    year_scaled_sample,\n",
    "    sim_mean_sample,\n",
    "    sim_max_sample,\n",
    "    sim_min_sample,\n",
    "    sim_std_sample\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_class_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# =========================\n",
    "# 6. MLflow & XGB\n",
    "# =========================\n",
    "mlflow.set_experiment(\"movies_reco_pipeline_classif\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_hybrid_classif\"):\n",
    "    params = {\n",
    "        \"n_estimators\": 300,\n",
    "        \"max_depth\": 6,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"auc\", auc)\n",
    "    mlflow.xgboost.log_model(model, \"xgb_classifier_model\")\n",
    "\n",
    "print(\"✅ Pipeline classification terminé ! Accuracy:\", acc, \"| AUC:\", auc)\n",
    "\n",
    "# =========================\n",
    "# 7. Sauvegarde des artefacts\n",
    "# =========================\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "joblib.dump(model, \"model/xgb_classifier_model.joblib\")\n",
    "print(\"✅ Modèle XGB sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du vectorizer\n",
    "joblib.dump(vectorizer, \"model/reco_vectorizer.joblib\")\n",
    "print(\"✅ TfidfVectorizer sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du SVD\n",
    "joblib.dump(svd_full, \"model/svd_model.joblib\")\n",
    "print(\"✅ SVD sauvegardé !\")\n",
    "\n",
    "# Sauvegarde de la TF-IDF matrix complète\n",
    "joblib.dump(tfidf_matrix_full, \"model/tfidf_matrix_full.joblib\")\n",
    "print(\"✅ TF-IDF matrix complète sauvegardée !\")\n",
    "\n",
    "# Sauvegarde du movie index\n",
    "df[[\"movie_id\", \"title\"]].to_csv(\"model/movie_index.csv\", index=False)\n",
    "print(\"✅ Movie index complet sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du MultiLabelBinarizer\n",
    "joblib.dump(mlb, \"model/mlb_model.joblib\")\n",
    "print(\"✅ MultiLabelBinarizer sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du StandardScaler pour l'année\n",
    "joblib.dump(scaler_year, \"model/scaler_year.joblib\")\n",
    "print(\"✅ StandardScaler pour l'année sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du NearestNeighbors complet\n",
    "joblib.dump(nn_full, \"model/nn_full.joblib\")\n",
    "print(\"✅ NearestNeighbors complet sauvegardé !\")\n",
    "\n",
    "# Sauvegarde du DataFrame complet\n",
    "df.to_csv(\"model/movies_full.csv\", index=False)\n",
    "print(\"✅ DataFrame complet sauvegardé !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b62c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score,\n",
    "#     roc_auc_score,\n",
    "#     precision_score,\n",
    "#     recall_score,\n",
    "#     f1_score,\n",
    "#     confusion_matrix,\n",
    "#     classification_report\n",
    "# )\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# import re\n",
    "# import mlflow\n",
    "# import mlflow.xgboost\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "\n",
    "# # =========================\n",
    "# # 1️⃣ Charger les données\n",
    "# # =========================\n",
    "# DATABASE_URL = \"mysql+pymysql://louve:%40Marley080922@mysql-louve.alwaysdata.net/louve_movies\"\n",
    "# engine = create_engine(DATABASE_URL)\n",
    "# query = \"SELECT title, synopsis, rating, genres, release_year FROM movies WHERE synopsis IS NOT NULL\"\n",
    "# df = pd.read_sql(query, engine)\n",
    "\n",
    "# # =========================\n",
    "# # 2️⃣ Nettoyage texte\n",
    "# # =========================\n",
    "# def preprocess_text(text: str) -> str:\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "#     return text\n",
    "\n",
    "# df[\"synopsis_clean\"] = df[\"synopsis\"].apply(preprocess_text)\n",
    "\n",
    "# # =========================\n",
    "# # 3️⃣ Like/Dislike\n",
    "# # =========================\n",
    "# threshold = 4.0\n",
    "# df[\"like_dislike\"] = df[\"rating\"].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "# # =========================\n",
    "# # 4️⃣ Features : TF-IDF + genres + année\n",
    "# # =========================\n",
    "# vectorizer = TfidfVectorizer(max_features=2000, stop_words=\"english\")\n",
    "# tfidf_matrix = vectorizer.fit_transform(df[\"synopsis_clean\"].fillna(\"\"))\n",
    "\n",
    "# df[\"genres_list\"] = df[\"genres\"].fillna(\"\").apply(lambda x: x.split(\"|\"))\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# genres_encoded = mlb.fit_transform(df[\"genres_list\"])\n",
    "\n",
    "# scaler_year = StandardScaler()\n",
    "# years_scaled = scaler_year.fit_transform(df[[\"release_year\"]].fillna(df[\"release_year\"].mean()))\n",
    "\n",
    "# X = np.column_stack([tfidf_matrix.toarray(), genres_encoded, years_scaled])\n",
    "# y = df[\"like_dislike\"].values\n",
    "\n",
    "# # =========================\n",
    "# # 5️⃣ Train/Test split\n",
    "# # =========================\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # Calcul du scale_pos_weight après train/test split\n",
    "# scale_pos_weight = y_train.tolist().count(0) / y_train.tolist().count(1)\n",
    "\n",
    "# # =========================\n",
    "# # 6️⃣ MLflow & XGBoost\n",
    "# # =========================\n",
    "# mlflow.set_experiment(\"movies_like_dislike_classif\")\n",
    "\n",
    "# with mlflow.start_run(run_name=\"xgb_like_dislike\"):\n",
    "#     # Log du seuil et du scale_pos_weight\n",
    "#     mlflow.log_param(\"like_threshold\", threshold)\n",
    "#     mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "\n",
    "#     # Paramètres du modèle\n",
    "#     params = {\n",
    "#         \"n_estimators\": 200,\n",
    "#         \"max_depth\": 5,\n",
    "#         \"learning_rate\": 0.05,\n",
    "#         \"random_state\": 42,\n",
    "#         \"n_jobs\": -1,\n",
    "#         \"use_label_encoder\": False,\n",
    "#         \"eval_metric\": \"logloss\",\n",
    "#         \"scale_pos_weight\": scale_pos_weight\n",
    "#     }\n",
    "#     mlflow.log_params(params)\n",
    "\n",
    "#     # Entraînement\n",
    "#     model = xgb.XGBClassifier(**params)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Prédictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#     # Metrics\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     roc = roc_auc_score(y_test, y_prob)\n",
    "#     prec = precision_score(y_test, y_pred)\n",
    "#     rec = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     report = classification_report(y_test, y_pred)\n",
    "\n",
    "#     # Log des métriques\n",
    "#     mlflow.log_metric(\"accuracy\", acc)\n",
    "#     mlflow.log_metric(\"roc_auc\", roc)\n",
    "#     mlflow.log_metric(\"precision\", prec)\n",
    "#     mlflow.log_metric(\"recall\", rec)\n",
    "#     mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "#     # Log du modèle\n",
    "#     mlflow.xgboost.log_model(model, \"xgb_like_dislike_model\")\n",
    "\n",
    "#     print(\"✅ Modèle loggé sur MLflow avec seuil et scale_pos_weight !\")\n",
    "\n",
    "# print(\"Accuracy:\", acc)\n",
    "# print(\"ROC AUC:\", roc)\n",
    "# print(\"Precision:\", prec)\n",
    "# print(\"Recall:\", rec)\n",
    "# print(\"F1-score:\", f1)\n",
    "# print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "# print(\"\\nClassification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
